{"model":{"opTime":1569227964,"supervised":0,"preprocess":1,"featureSelect":0,"classifier":0,"regressor":0,"cluster":0,"timeSeries":0,"mining":0,"pythonClass":"mine_tf_fullconnect","pythonClassImport":"import tensorflow as tf","pythonClassDefine":"class mine_tf_fullconnect:\n    def __init__(self):\n        self._params = {}\n        self.vars = {}\n        self.out = None\n\n    def get_params(self, deep=True):\n        return self._params\n\n    def set_params(self, **params):\n        for (k, v) in params.items():\n            self._params[k] = v\n\n    def fit(self, data, y=None):\n        return self\n\n    def transform(self, data):\n        return data\n\n    def __getstate__(self):\n        return self._params\n\n    def __setstate__(self, state):\n        self._params = state\n\n    def build(self, in_node, y_true, feed_dict_train, feed_dict_test):\n        in_shape = in_node.shape.as_list()\n        if len(in_shape) > 2:\n            d = 1\n            for i in range(1, len(in_shape)):\n                d *= in_shape[i]\n            in_node = tf.reshape(in_node, [-1, d])\n            in_shape = in_node.shape.as_list()\n\n        in_dim = in_shape[1]\n        out_dim = int(self._params.get('out_dim'))\n        kernel_initializer = self._params.get('kernel_initializer', 'zeros')\n        kernel_initializer_arg = self._params.get('kernel_initializer_arg')\n        bias_initializer = self._params.get('bias_initializer', 'zeros')\n        bias_initializer_arg = self._params.get('bias_initializer_arg')\n        activation = self._params.get('activation')\n        kernel_l2_wd = self._params.get('kernel_l2_wd')\n\n        if kernel_initializer == 'one':\n            kernel = tf.Variable(tf.one([in_dim, out_dim]))\n        elif kernel_initializer == 'constant':\n            kernel = tf.Variable(tf.constant(float(kernel_initializer_arg), shape=[in_dim, out_dim]))\n        elif kernel_initializer == 'truncated_normal':\n            kernel = tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=float(kernel_initializer_arg)))\n        else:  # default 'zeros'\n            kernel = tf.Variable(tf.zeros([in_dim, out_dim]))\n\n        if bias_initializer == 'one':\n            bias = tf.Variable(tf.one([out_dim]))\n        elif bias_initializer == 'constant':\n            bias = tf.Variable(tf.constant(float(bias_initializer_arg), shape=[out_dim]))\n        elif bias_initializer == 'truncated_normal':\n            bias = tf.Variable(tf.truncated_normal([out_dim], stddev=float(bias_initializer_arg)))\n        else:  # default 'zeros'\n            bias = tf.Variable(tf.zeros([out_dim]))\n\n        out = tf.matmul(in_node, kernel) + bias\n        if activation == 'softmax':\n            self.out = tf.nn.softmax(out)\n        elif activation == 'relu':\n            self.out = tf.nn.relu(out)\n        else:\n            self.out = out\n\n        self.vars['kernel'] = kernel\n        self.vars['bias'] = bias\n\n        if kernel_l2_wd is not None:\n            tf.add_to_collection('losses', tf.multiply(tf.nn.l2_loss(kernel), float(kernel_l2_wd)))","desc":"tf 全连接","inputParams":[{"name":"out_dim","valueSet":"I>0","defaultValue":"","candidateValues":"","desc":"输出维度","option":0},{"name":"kernel_initializer","valueSet":"'zeros' 'one' 'truncated_normal' 'constant'","defaultValue":"'zeros'","candidateValues":"","desc":"核矩阵初始化","option":1},{"name":"bias_initializer","valueSet":"'zeros' 'one' 'truncated_normal' 'constant'","defaultValue":"'zeros'","candidateValues":"","desc":"偏移向量初始化","option":1},{"name":"activation","valueSet":"None 'softmax' 'relu'","defaultValue":"None","candidateValues":"","desc":"激励","option":1},{"name":"kernel_initializer_arg","valueSet":"None str","defaultValue":"None","candidateValues":"","desc":"核矩阵初始化参数","option":1},{"name":"bias_initializer_arg","valueSet":"None str","defaultValue":"None","candidateValues":"","desc":"偏移向量初始化参数","option":1},{"name":"kernel_l2_wd","valueSet":"R>0","defaultValue":"","candidateValues":"","desc":"kernel 系数 l2 正则化衰减系数","option":1}],"studyParams":[],"useExample":""}}